{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance and Correlation - Lab\n",
    "\n",
    "In this lab, we shall working towards calculating covariance and correlation for a given dataset in python. We shall use the formulas shown in previous lesson and verify our results with python libraries.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to \n",
    "* Calculate and and interpret correlation and covariance for given variables\n",
    "* Build density and scatter plots to visually identify the level of dependence between variables\n",
    "* Perform covariance and correlation using python and numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Included dataset (heightWeight.csv) includes 20 heights (inches) and weights(pounds). Yes, it is a particularly small dataset and will help us focus more on seeing covariance and correlation in action. At this point, you should be able to calculate the average height and average weight. You can also explain the medians, variances and standard deviations for this dataset.\n",
    "\n",
    "But all of those measurements are only concerned with a **single variable**. What if we want to see: \n",
    "\n",
    "How height interacts with weight ? \n",
    "\n",
    "Does weight increase as height increases ?\n",
    "\n",
    "Are Weight and Height not related at all ?\n",
    "\n",
    "Note while there are plenty of fat short people and overly skinny tall people, but when you look at the population at large, taller people will tend to weigh more than shorter people. This generalization of information is very common as it shows you a bigger picture that you can build your intuitions upon.\n",
    "\n",
    "Let's first load this dataset into pandas. Read the file \"heightWeight.csv\" and for header, length of the records and basic stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.850000</td>\n",
       "      <td>165.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.112163</td>\n",
       "      <td>28.971129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.250000</td>\n",
       "      <td>143.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.500000</td>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>192.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          height      Weight\n",
       "count  20.000000   20.000000\n",
       "mean   66.850000  165.800000\n",
       "std     5.112163   28.971129\n",
       "min    58.000000  115.000000\n",
       "25%    63.250000  143.750000\n",
       "50%    68.500000  170.000000\n",
       "75%    71.000000  192.750000\n",
       "max    74.000000  210.000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into pandas and perform basic inspection\n",
    "import pandas as pd\n",
    "data =pd.read_csv('heightWeight.csv')\n",
    "data.head()\n",
    "data.describe()\n",
    "\n",
    "# 20\n",
    "#    height  Weight\n",
    "# 0      68     165\n",
    "# 1      71     201\n",
    "# 2      61     140\n",
    "# 3      69     170\n",
    "# 4      71     192\n",
    "#           height      Weight\n",
    "# count  20.000000   20.000000\n",
    "# mean   66.850000  165.800000\n",
    "# std     5.112163   28.971129\n",
    "# min    58.000000  115.000000\n",
    "# 25%    63.250000  143.750000\n",
    "# 50%    68.500000  170.000000\n",
    "# 75%    71.000000  192.750000\n",
    "# max    74.000000  210.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate covariance \n",
    "\n",
    "Here's the covariance formula once again. \n",
    "\n",
    "![](cov2.png)\n",
    "\n",
    "We would use (n-1) due to the fact that we are working with samples of a bigger population here. \n",
    "\n",
    "#### Mean normalization \n",
    "\n",
    "But before we do this, we have to ensure the that both variables are **Mean Normalized** (as shown in the numerator above). i.e. both variables have mean values = 0 . This allows us to calculate how much they vary while disregarding their distance from each other. A bit like standardization that we saw before, but here we are not standardizing the spread (standard deviation), as that is what needs to be studied. So the formula to mean normalize a data set is : \n",
    "\n",
    "> **xi - X(mean)**\n",
    "\n",
    "Pretty simple, take each element of the variable and subtract the mean value from it. This will create a new \"mean-normalized\" dataset. Let's write a function that takes in a vector, calculates the mean of vector and subtracts the calculated mean value from each element to calculate xi - X(mean). \n",
    "\n",
    "Hint: use `np.mean()` to calculate the mean for above formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-2.0, -1.0, 0.0, 1.0, 2.0], [-22.0, -11.0, 0.0, 11.0, 22.0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Write a function to take in an iterable, calculate the mean and subtract the mean value\n",
    "# from each element , creating and returning a new list. \n",
    "\n",
    "def mean_normalize(var):\n",
    "    new_var = []\n",
    "    mu = np.mean(var)\n",
    "    for t in var:\n",
    "        new_var.append(t - mu)\n",
    "    return new_var\n",
    "\n",
    "mean_normalize([1,2,3,4,5]), mean_normalize([11,22,33,44,55])\n",
    "\n",
    "# ([-2.0, -1.0, 0.0, 1.0, 2.0], [-22.0, -11.0, 0.0, 11.0, 22.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great so you see, our function maintains the variance of list elements and moves their mean to zero. As a quick test, we can visualize what exactly happens to the data with mean normalization. Plot the height variable distribution before and after the normalization process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 32.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from seaborn) (1.15.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from seaborn) (3.0.2)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from seaborn) (0.23.4)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2018.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.0.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.9.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2064f4b5f8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Visualize the height data distribution before and after mean normalization \n",
    "height = mean_normalize(data.height)\n",
    "import seaborn as sns\n",
    "sns.distplot(data.height)\n",
    "sns.distplot(height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there you go, not much changes in the shape of the data. Try repeating above with weight. \n",
    "\n",
    "#### The dot product\n",
    "\n",
    "So now that we have our new normalized datasets. According to the numerator in the formula,we have to take the **DOT PRODUCT** of these two vector values. A dot product  let's us apply the directional growth of one vector to another. Dot products are very important in vector calculus for a number of applications. [Here is a great article explaining this in detail](https://betterexplained.com/articles/vector-calculus-understanding-the-dot-product/). \n",
    "\n",
    "For two vectors a and b, a dot product is calculated by multiplying each element of one vector to its counterpart in the second , and then adding them up together.  \n",
    "```\n",
    " a[0] * b[0] + a[1] * b[1] + a[2] * b[2] ...\n",
    "\n",
    "```\n",
    "\n",
    "So lets write a function that will take two iterables and return their dot product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function to calculate the dot product of two iterables \n",
    "\n",
    "def dot_product(x,y):\n",
    "    s = 0\n",
    "    for q,w in zip(x,y):\n",
    "        s += q*w\n",
    "    return s\n",
    "\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "\n",
    "dot_product(a,b)\n",
    "\n",
    "#  32  calculated as (1*4 + 2*5 + 3*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have the numerator of the formula sorted out. Let's finally write a function `covariance()` that will take height and weight lists we created earlier and return the covariance value using the functions we created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.75789473684208"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate covariance using functions above\n",
    "\n",
    "def covariance(var1, var2):\n",
    "    \n",
    "    x = mean_normalize(var1)\n",
    "    y = mean_normalize(var2)\n",
    "\n",
    "    result = dot_product(x,y)\n",
    "\n",
    "    return result /((len(var1)) -1)\n",
    "\n",
    "\n",
    "\n",
    "# Uncomment below to check your function\n",
    "\n",
    "covariance(data['height'], data['Weight'])\n",
    "\n",
    "# 144.75789473684208"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify our results with pandas built in `dataFrame.cov()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>26.134211</td>\n",
       "      <td>144.757895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>144.757895</td>\n",
       "      <td>839.326316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            height      Weight\n",
       "height   26.134211  144.757895\n",
       "Weight  144.757895  839.326316"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment to run\n",
    "data.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so covariance (as well as correlation) are usually shown in matrix form. the covariance between height and weight is exactly what we calculated. the matrix also shows the covariance of a variable with itself. So this gives us magnitude which is a bit hard to interpret. How about we visualize height and weight on a scatter plot ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scatter graph between height and weight to visually inspect the relationship "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2064bd3dd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(data.height, data.Weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see there is quite a bit of positive relationship between the two, but a covariance value is a bit hard to interpret. So let's try calculating correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Correlation\n",
    "\n",
    "Once again, heres the formula to calculate the correlation. \n",
    "![](cor.png)\n",
    "\n",
    "lots of mean normalizations going on here. It shouldn't be too hard now to implement this using our functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Correlation between two variables using formula above\n",
    "import math\n",
    "def correlation(var1,var2):\n",
    "    x_norm = mean_normalize(var1)\n",
    "    y_norm = mean_normalize(var2)\n",
    "    \n",
    "    num = dot_product(x_norm,y_norm)\n",
    "    x_sqr = sum([x**2 for x in x_norm])\n",
    "    y_sqr = sum([y**2 for y in y_norm])\n",
    "    denom = (x_sqr*y_sqr)**.5\n",
    "    return num/denom\n",
    "\n",
    "correlation(data['height'], data['Weight'])\n",
    "\n",
    "# 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, 0.98, thats very close to one. So that means height and weight are like TOTALLY dependent on each other. Well, only for this particular sample. And there is a takeaway in this. sample size plays a major rule in determining the nature of a variable and its relationship with other variables. the set of 20 records we have seem to correlate highly, but this might be different for a different set of samples. We shall talk about how to further test such a finding to either reject it , or confirm it as a FACT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last check , let's use pandas `dataframe.corr()` method to see how that works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>0.9774</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        height  Weight\n",
       "height  1.0000  0.9774\n",
       "Weight  0.9774  1.0000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment to run\n",
    "# data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another matrix similar to above. And we see that a correlation of a variable to itself will always be = 1. The correlation between height and weight can be rounded off to our results. That is great. Now we know how this works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lab we saw how to calculate the covariance and correlation between variables. We also looked at mean normalization and dot products which will be revisited later in the course. FInally we saw how to calculate these measures using pandas built in methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
